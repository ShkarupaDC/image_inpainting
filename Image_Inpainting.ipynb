{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Inpainting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMMUEVxmy/yvotQoNjHmxL3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ShkarupaDC/image_inpainting/blob/master/Image_Inpainting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQk1-YWu7M5s"
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from torch import nn\n",
        "from collections import namedtuple"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tt2Yuw2-AAn"
      },
      "source": [
        "class PConv2d(nn.Conv2d):\n",
        "\n",
        "\n",
        "  def __init__(self, *args, **kwargs):\n",
        "    \n",
        "    if \"return_mask\" in kwargs:\n",
        "      \n",
        "      self.return_mask = kwargs[\"return_mask\"]\n",
        "      kwargs.pop(\"return_mask\")\n",
        "    \n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.window = self.in_channels * self.out_channels *\\\n",
        "          self.kernel_size[0] * self.kernel_size[0]\n",
        "    \n",
        "    self.mask_kernel = torch.ones(self.out_channels,\n",
        "          self.in_channels, *self.kernel_size)\n",
        "\n",
        "\n",
        "  def forward(self, x, mask=None):\n",
        "\n",
        "    with torch.no_grad():\n",
        "      if mask is not None:\n",
        "\n",
        "        updated_mask = F.conv2d(mask, self.mask_kernel, None,\n",
        "            self.stride, self.padding, self.dilation)\n",
        "        \n",
        "        mask_ratio = self.window / (updated_mask + 1e-6)\n",
        "        \n",
        "        updated_mask = torch.clamp(updated_mask, 0, 1)\n",
        "        mask_ratio = torch.mul(updated_mask, mask_ratio)\n",
        "    \n",
        "    x = super().forward(x if mask is None else torch.mul(x, mask))\n",
        "\n",
        "    if self.bias is not None:\n",
        "      \n",
        "      bias_view = self.bias.view(1, self.out_channels, 1, 1)\n",
        "      x = torch.mul(x, mask_ratio) + bias_view\n",
        "\n",
        "    else: x = torch.mul(x, mask_ratio)\n",
        "\n",
        "    if self.return_mask is True: return (x, updated_mask)\n",
        "    \n",
        "    else: return x"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVYCG6dcFIpW"
      },
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size,\n",
        "      stride=1, padding=0, bn=True, activation=nn.ReLU()):\n",
        "    super().__init__()\n",
        "\n",
        "    self.pconv = PConv2d(in_channels, out_channels,\n",
        "        kernel_size, stride, padding, return_mask=True)\n",
        "    \n",
        "    if bn is True:\n",
        "      self.bn = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    self.activation = activation\n",
        "\n",
        "  \n",
        "  def forward(self, x, mask):\n",
        "    \n",
        "    x, mask = self.pconv(x, mask)\n",
        "\n",
        "    if hasattr(self, \"bn\"):\n",
        "      x = self.bn(x)\n",
        "\n",
        "    x = self.activation(x)\n",
        "    \n",
        "    return x, mask"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VLnCftLTFaSF"
      },
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "\n",
        "  def __init__(self, in_channels, out_channels, kernel_size,\n",
        "    stride=1, padding=0, bn=True, activation=nn.LeakyReLU(0.2)):\n",
        "\n",
        "    self.pconv = PConv2d(in_channels, out_channels,\n",
        "      kernel_size, stride, padding, return_mask=True)\n",
        "    \n",
        "    if bn is True:\n",
        "      self.bn = nn.BatchNorm2d(out_channels * 2)\n",
        "\n",
        "    self.activation = activation\n",
        "\n",
        "\n",
        "  def forward(self, x, mask, encoded_x, encoded_mask):\n",
        "\n",
        "    x = F.upsample_nearest(x, (2, 2))\n",
        "    mask = F.upsample_nearest(mask, (2, 2))\n",
        "\n",
        "    x = torch.cat([x, encoded_x], dim=-1)\n",
        "    mask = torch.cat([mask, encoded_mask], dim=-1)\n",
        "\n",
        "    if hasattr(self, \"bn\"): x = self.bn(x)\n",
        "    x = self.activation(x)\n",
        "\n",
        "    return x, mask\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cmoyEhXtLSH"
      },
      "source": [
        "UNetBlock = namedtuple(\"UNetBlock\", [\"in_channels\", \"out_channels\",\n",
        "    \"kernel_size\", \"stride\", \"padding\", \"dilation\", \"bn\"])\n",
        "\n",
        "EncoderBlock = [\n",
        "  UNetBlock(3, 64, 7, 2, 3, 1, False), UNetBlock(64, 128, 5, 2, 2, 1, True),\n",
        "  UNetBlock(128, 256, 3, 2, 1, 1, True), UNetBlock(256, 512, 3, 2, 1, 1, True),\n",
        "  UNetBlock(512, 512, 3, 2, 1, 1, True), UNetBlock(512, 512, 3, 2, 1, 1, True),\n",
        "  UNetBlock(512, 512, 3, 2, 1, 1, True), UNetBlock(512, 512, 3, 2, 1, 1, True)\n",
        "]\n",
        "\n",
        "DecoderBlock = [\n",
        "  UNetBlock(1024, 512, 3, 2, 1, 1, True), UNetBlock(1024, 512, 3, 2, 1, 1, True),\n",
        "  UNetBlock(1024, 512, 3, 2, 1, 1, True), UNetBlock(1024, 512, 3, 2, 1, 1, True),\n",
        "  UNetBlock(768, 256, 3, 2, 1, 1, True), UNetBlock(384, 128, 3, 2, 1, 1, True),\n",
        "  UNetBlock(192, 64, 3, 2, 1, 1, True), UNetBlock(67, 3, 3, 2, 1, 1, False)\n",
        "]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LE8jiyQQOJjY"
      },
      "source": [
        "class UNetModule(nn.Module):\n",
        "\n",
        "  def __init__(self, e_blocks, d_blocks):\n",
        "    super().__init__()\n",
        "\n",
        "    self.e_layers, self.d_layers = [], []\n",
        "    blocks = zip(e_blocks, d_blocks)\n",
        "\n",
        "    for idx, (e_block, d_block) in enumerate(blocks):\n",
        "      \n",
        "      self.e_layers.append(EncoderLayer(*e_block))\n",
        "      self.d_layers.append(DecoderLayer(*d_block))\n",
        "\n",
        "    self.e_layers = nn.ModuleList(self.e_layers)\n",
        "    self.d_layers = nn.ModuleList(self.d_layers)\n",
        "\n",
        "  def forward(self, x, mask):\n",
        "    \n",
        "    encoded = [(x, mask)]\n",
        "\n",
        "    for e_layer in self.e_layers:\n",
        "      x, mask = e_layer(x, mask)\n",
        "      encoded.append((x, mask))\n",
        "\n",
        "    for idx, d_layer in enumerate(self.d_layers):\n",
        "      x, mask = d_layer(x, mask, *encoded[-(idx + 1)])\n",
        "\n",
        "    return x, mask\n"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18HxNPx2zKcN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}